#### Parser ####

# 1. Seperate the syntax into individual expressions with tokens
  # 1.1 Split syntax into individual lines
  # 1.2 Split the lines into chr_vectors containing tokens
  # 1.3 Remove the comments from the lines
  # 1.4 Merge into one function


# 2. Parse the Lines
  # 2.1 Parse individual lines
    # 2.1.1 check if the first token is an object
      # if not return error
    # 2.1.2 Check the next token to see whether it is an operator
      # If not, return error
    # 2.1.2 Call the parsing function belonging to the operator.

example <- "
X =~ x1 + lbl1*x2 # This is a comment
Y =~ 1*y1 + y2
# this is also a comment, before an empty line

Z =~ z1 + z2
Y ~  X + Z + X:Z
x1 ~ 1
x1 ~~ x2
"


# 1. Seperate the syntax into individual lines ####

  # 1.1 Split the lines into chr_vectors containing tokens

sepLines <- function(modelSyntax) {
  # seperate the lines of a lavaan syntax
  unlist(strsplit(modelSyntax, "\\n"))
}



  # 1.2 Split the lines into chr_vectors containing tokens

    # 1.2.1 Solving for indivdiul lines

getTokensLine <- function(line) {
  # get the tokens of an individual line/expression from the lavaan syntax
  # example: getTokens("model =~ x1 + x2")

  unlist(strsplit(line, "\\s+|\\n"))
}



    # 1.2.2 Solving for multiple lines

getTokensSyntax <- function(modelSyntax) {
  # get the tokens of a modelSyntax
    # example: getTokensSyntax(example)

  # Getting a vector with the individual lines
  lines <- sepLines(modelSyntax)

  # Creating a list where the containing the tokens for the respective lines
  lapply(lines, getTokensLine)
}



  # 1.3 Remove the comments from the lines

    # 1.3.1 Solving for a single line

removeCommentsLine <- function(chr_vec) {
  # remove exressions from a chr_vec (representing a line, not the whole model)
    # example: getTokensLine("x + y + h + hello # this is a comment") |> removeCommentsLine()

  # If null return NULL
  if (is.null(chr_vec)) return(NULL)

  # Break recursion at the end
  if (length(chr_vec) <= 1) return(chr_vec)

  # check first element
  if (chr_vec[[1]] == "#") return(NULL)

  # recurse down the rest of the vector
  rest <- removeCommentsLine(chr_vec[-1])

  # return first element, with the rest recursed
  return(c(chr_vec[[1]], rest))

}



    # 1.3.2 Solving for multiple lines

removeCommentsMultLines <- function(listLines) {
  # remove the comments from a list containing the tokens of individual lines
    # example getTokensSyntax(example) |> removeCommentsMultLines()
  lines <- lapply(listLines, removeCommentsLine)

  # Remove lines which are NULL or length = 0 (i.e., character(0))
    # create a logical vector marking empty elements
  logical <- unlist(lapply(lines, function(x) is.null(x) | length(x) == 0))

  # return non-empty elements
  lines[!logical]
}



# 1.4 Merge into one function

  getModelExpressions <- function(modelSyntax) {
    # Get the individual expressions in token-form from a modelSyntax with removed comments
      # Example: getModelExpressions(example)

    # Get Lines with tokens
    linesWithTokens <- getTokensSyntax(modelSyntax)

    # Return with removed comments (out = list)
    removeCommentsMultLines(linesWithTokens)
  }






#### 2. Parse the Lines ####

  # 2.1 Parse individual lines

    # 2.1.1 Create functions for identifying token-types

      # find tokentype
  tokenType <- function(token) {
    # it would be nice to use switch() here, but it wont allow regex
    if (length(token) != 1) return(errorCondition("something went wrong when evaluating token, token not length = 1"))

    # Check if pattern matches object or label
    if (grepl("^[[:alpha:]](|[[:alnum:]])", token)) "lavName"
    # Chek if it is int

    else if (grepl("^[[:digit:]]$", token)) "lavInt"

    # Check if is specifyIndicators
    else if (token == "=~") "lavSpecifyIndicators"

    # Check if token is Add
    else if (token == "+") "lavAdd"

    # Check if token is covariance
    else if (token == "~~") "lavCov"

    # Check if token is Predict
    else if (token == "~") "lavPredict"

    # Check if token is * / fixValue
    else if (token == "*") "fixValue"

    # unmatched
    else errorCondition("unidentified token")
  }




        # Check if a token is an operator
  is.lavOperator <- function(token) {
    token %in% c(specifyIndicators  = "=~",
                 predictVariable   = "~",
                 covariance        = "~~",
                 fixValue          = "*",
                 add               = "+")
  }



    # Identify what type of expression you have in a line, and chose the correct parsing function

parseLeftRight <- function(expression) {
  # recursive function for parsing a line

  if (is.null(expression)) return(NULL)
  if (length(expression) < 3) return(errorCondition(paste0(expression, "too short")))

  # Check if first token is a name/object
  if (tokenType(expression[[1]]) != "lavName") return(errorCondition(paste0("expected lavObject, not ", expression[[1]])))

  # Check if second token is a operator
  if (!is.lavOperator(expression[[2]])) return(errorCondition(paste0("expected operator in ", expression)))
  class(expression) <- tokenType(expression[[2]])
  operator(expression)
}



operator <- function(expression) {
  UseMethod("operator")
}



 # function for reading an expression following: "latentName =~"
operator.lavSpecifyIndicators <- function(expression) {
  latentName <- expression[[1]]

}

    # 2.1.2 Check the next token to see whether it is an operator/what operator it is

      # 2.1.2.1 basic function for evaluating token


 getLavOperator <- function(token) {
   # get The operator of a token, if not a operator return FALSE

   # labelled vector with operators
   operators <- c(specifyIndicators  = "=~",
                   predictVariable   = "~",
                   covariance        = "~~",
                   fixValue          = "*",
                   add               = "+")

   # select operator, in case something goes wrong i select the first element of the output.
   operator <- operators[token == operators][1]

   # If operator is not found (NA) return FALSE
   if (is.na(operator)) return(FALSE)

   # Return the label of the operator which will be used to call method
   labels(operator)
  }

    # If not, return error
    # 2.1.2 Call the parsing function belonging to the operator.





parseLine <- function(chr_v) {
  # read a chr_vec containing tokens

}

# Patterns for classifying tokens
grammarPatterns <- list(
  objects = "^[:alpha:](|[:alnum:])"
)


peekToken <- function(chr_v, i, k = 1) {
  # look at the next token from left to right
  chr_v[[i+k]]
}

